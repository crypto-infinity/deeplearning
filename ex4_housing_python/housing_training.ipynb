{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<strong>Dependencies installation</strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from pandas) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: numpy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (1.23.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (4.25.3)\n",
            "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.30.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow) (7.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow) (3.19.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-metrics in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (0.1.0)\n",
            "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-metrics) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-learn->scikit-metrics) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-learn->scikit-metrics) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-learn->scikit-metrics) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from scikit-learn->scikit-metrics) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting tensorflow_datasets\n",
            "  Downloading tensorflow_datasets-4.9.3-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: absl-py in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (2.1.0)\n",
            "Collecting array-record (from tensorflow_datasets)\n",
            "  Downloading array_record-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (699 bytes)\n",
            "Requirement already satisfied: click in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (8.1.7)\n",
            "Collecting dm-tree (from tensorflow_datasets)\n",
            "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
            "  Downloading etils-1.5.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (1.23.5)\n",
            "Collecting promise (from tensorflow_datasets)\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (4.25.3)\n",
            "Requirement already satisfied: psutil in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (5.9.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (2.32.3)\n",
            "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
            "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: termcolor in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (2.4.0)\n",
            "Collecting toml (from tensorflow_datasets)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (4.66.4)\n",
            "Requirement already satisfied: wrapt in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from tensorflow_datasets) (1.14.1)\n",
            "Requirement already satisfied: fsspec in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2024.6.0)\n",
            "Requirement already satisfied: importlib_resources in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.12.2)\n",
            "Requirement already satisfied: zipp in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.6.2)\n",
            "Requirement already satisfied: six in /anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
            "Collecting protobuf>=3.20 (from tensorflow_datasets)\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (679 bytes)\n",
            "Downloading tensorflow_datasets-4.9.3-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading etils-1.5.2-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading array_record-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
            "Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: promise\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=3714fd5cc76cbb9411c2a73b10cf6d98b78b387733f156bc5dd2b82c663b0975\n",
            "  Stored in directory: /home/azureuser/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
            "Successfully built promise\n",
            "Installing collected packages: dm-tree, toml, protobuf, promise, etils, tensorflow-metadata, array-record, tensorflow_datasets\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.3\n",
            "    Uninstalling protobuf-4.25.3:\n",
            "      Successfully uninstalled protobuf-4.25.3\n",
            "Successfully installed array-record-0.5.1 dm-tree-0.1.8 etils-1.5.2 promise-2.3 protobuf-3.20.3 tensorflow-metadata-1.15.0 tensorflow_datasets-4.9.3 toml-0.10.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install numpy\n",
        "%pip install tensorflow\n",
        "%pip install scikit-learn\n",
        "%pip install scikit-metrics\n",
        "%pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<strong>Dependencies import</strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1722255768374
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras import layers, models # type: ignore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importazione del dataset\n",
        "\n",
        "dataset_url = \"https://raw.githubusercontent.com/timothypesi/Data-Sets-For-Machine-Learning-/main/california_housing_train.csv\"\n",
        "df = pd.read_csv(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Suddivisione del dataset in training set e test set\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparazione dei dati per il modello TensorFlow\n",
        "\n",
        "train_labels = train_df.pop('median_house_value')\n",
        "test_labels = test_df.pop('median_house_value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/engine/base_preprocessing_layer.py\", line 122, in adapt_step  *\n        self._adapt_maybe_build(data)\n    File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/engine/base_preprocessing_layer.py\", line 295, in _adapt_maybe_build  **\n        self.build(data_shape)\n    File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/layers/preprocessing/normalization.py\", line 173, in build\n        input_shape = tf.TensorShape(input_shape).as_list()\n\n    ValueError: as_list() is not defined on an unknown TensorShape.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Normalizzazione dei dati\u001b[39;00m\n\u001b[1;32m      7\u001b[0m normalizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mNormalization()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mnormalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#   def input_function():  # inner function, this will be returned\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     return ds  # return a batch of the dataset\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#   return input_function  # return a function object for use\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/layers/preprocessing/normalization.py:287\u001b[0m, in \u001b[0;36mNormalization.adapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madapt\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the mean and variance of values in a dataset.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    Calling `adapt()` on a `Normalization` layer is an alternative to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m          argument is not supported with array inputs.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/engine/base_preprocessing_layer.py:258\u001b[0m, in \u001b[0;36mPreprocessingLayer.adapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m--> 258\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adapt_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m    260\u001b[0m             context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/tmp/__autograph_generated_fileosinehsh.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__adapt_step\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mFunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madapt_step\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mConversionOptions(recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, user_requested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optional_features\u001b[38;5;241m=\u001b[39m(), internal_convert_user_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;28;01mas\u001b[39;00m fscope:\n\u001b[1;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mnext\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(iterator),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 10\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_adapt_maybe_build, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/engine/base_preprocessing_layer.py:295\u001b[0m, in \u001b[0;36mPreprocessingLayer._adapt_maybe_build\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_input_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# Set the number of dimensions.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_input_shape \u001b[38;5;241m=\u001b[39m data_shape_nones\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/layers/preprocessing/normalization.py:173\u001b[0m, in \u001b[0;36mNormalization.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_shape, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(shape, tf\u001b[38;5;241m.\u001b[39mTensorShape) \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m input_shape\n\u001b[1;32m    166\u001b[0m ):\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalization only accepts a single input. If you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a python list or tuple as a single input, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease convert to a numpy array or `tf.Tensor`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorShape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_shape)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(a \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mndim \u001b[38;5;129;01mor\u001b[39;00m a \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m ndim \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis):\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/engine/base_preprocessing_layer.py\", line 122, in adapt_step  *\n        self._adapt_maybe_build(data)\n    File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/engine/base_preprocessing_layer.py\", line 295, in _adapt_maybe_build  **\n        self.build(data_shape)\n    File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/keras/src/layers/preprocessing/normalization.py\", line 173, in build\n        input_shape = tf.TensorShape(input_shape).as_list()\n\n    ValueError: as_list() is not defined on an unknown TensorShape.\n"
          ]
        }
      ],
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((dict(train_df), train_labels))\n",
        "ds = ds.batch(32).repeat(200)\n",
        "\n",
        "feature_ds = ds.map(lambda x, y: x)\n",
        "# Normalizzazione dei dati\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization()\n",
        "normalizer.adapt(feature_ds, batch_size=32, steps=200) #ERROR\n",
        "\n",
        "\n",
        "# def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "#   def input_function():  # inner function, this will be returned\n",
        "#     ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
        "#     if shuffle:\n",
        "#       ds = ds.shuffle(1000)  # randomize order of data\n",
        "#     ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "#     return ds  # return a batch of the dataset\n",
        "#   return input_function  # return a function object for use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Costruzione del modello ANN con TensorFlow\n",
        "\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "\n",
        "model = models.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(200, activation='relu'),\n",
        "    layers.Dense(200, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='mse')\n",
        "\n",
        "# Addestramento del modello\n",
        "#model.fit(train_df, train_labels, epochs=200, validation_split=0.2) \n",
        "\n",
        "model.fit(ds, epochs=200) \n",
        "\n",
        "#notes:\n",
        "# loss converges at epoch 199, after that increases again\n",
        "# SGD not working\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valutazione del modello sul test set\n",
        "\n",
        "loss = model.evaluate(test_df, test_labels)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predizione dei valori sul test set\n",
        "\n",
        "test_predictions = model.predict(test_df).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggiunta delle predizioni al test set\n",
        "\n",
        "test_df['predicted_median_house_value'] = test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvataggio del modello e dei risultati\n",
        "\n",
        "model.save(\"Users/g.scorpaniti/notebook/ex4_housing_python/artifacts/model/model.keras\")\n",
        "test_df.to_csv(\"Users/g.scorpaniti/notebook/ex4_housing_python/artifacts/test_set.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcolo degli indicatori R2 e MSA\n",
        "\n",
        "r2 = r2_score(test_labels, test_predictions)\n",
        "msa = mean_squared_error(test_labels, test_predictions)\n",
        "\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "print(f\"Mean Squared Error: {msa:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - Pytorch and Tensorflow",
      "language": "python",
      "name": "python38-azureml-pt-tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
